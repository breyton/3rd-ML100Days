{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python [conda env:tf18_keras]","language":"python","name":"conda-env-tf18_keras-py"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.5"},"colab":{"name":"Day100_transfer_learning TPU BS64.ipynb","provenance":[{"file_id":"1t9Bx6xxOZzBIMuSWvmY_Gm0WCcL2ewWA","timestamp":1576913847931},{"file_id":"1SgKhCr52gkvkC1QhKR3VBe332-zpJZeo","timestamp":1576906892677}],"collapsed_sections":[]},"accelerator":"TPU"},"cells":[{"cell_type":"code","metadata":{"id":"lC6cDbsemGqW","colab_type":"code","colab":{}},"source":["from tensorflow.keras.datasets import cifar10\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.utils import to_categorical"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"FZo9fxR0s_WZ","colab_type":"code","colab":{}},"source":["import os\n","import pprint\n","import tensorflow as tf\n","import tensorflow.keras\n","from tensorflow.keras.layers import Dense, Conv2D, BatchNormalization, Activation\n","from tensorflow.keras.layers import AveragePooling2D, Input, Flatten\n","from tensorflow.keras.regularizers import l2\n","from tensorflow.keras import backend as K\n","from tensorflow.keras.models import Model"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"RfZf1B8YmJFP","colab_type":"code","colab":{}},"source":["def resnet_layer(inputs,\n","                 num_filters=16,\n","                 kernel_size=3,\n","                 strides=1,\n","                 activation='relu',\n","                 batch_normalization=True,\n","                 conv_first=True):\n","    \"\"\"2D Convolution-Batch Normalization-Activation stack builder\n","    # Arguments\n","        inputs (tensor): input tensor from input image or previous layer\n","        num_filters (int): Conv2D number of filters\n","        kernel_size (int): Conv2D square kernel dimensions\n","        strides (int): Conv2D square stride dimensions\n","        activation (string): activation name\n","        batch_normalization (bool): whether to include batch normalization\n","        conv_first (bool): conv-bn-activation (True) or\n","            bn-activation-conv (False)\n","    # Returns\n","        x (tensor): tensor as input to the next layer\n","    \"\"\"\n","    conv = Conv2D(num_filters,\n","                  kernel_size=kernel_size,\n","                  strides=strides,\n","                  padding='same',\n","                  kernel_initializer='he_normal',\n","                  kernel_regularizer=l2(1e-4))\n","\n","    x = inputs\n","    if conv_first:\n","        x = conv(x)\n","        if batch_normalization:\n","            x = BatchNormalization()(x)\n","        if activation is not None:\n","            x = Activation(activation)(x)\n","    else:\n","        if batch_normalization:\n","            x = BatchNormalization()(x)\n","        if activation is not None:\n","            x = Activation(activation)(x)\n","        x = conv(x)\n","    return x\n","\n","def resnet(input_shape, depth=29, num_classes=10):\n","    \"\"\"ResNet Version 2 Model builder [b]\n","    Stacks of (1 x 1)-(3 x 3)-(1 x 1) BN-ReLU-Conv2D or also known as\n","    bottleneck layer\n","    First shortcut connection per layer is 1 x 1 Conv2D.\n","    Second and onwards shortcut connection is identity.\n","    At the beginning of each stage, the feature map size is halved (downsampled)\n","    by a convolutional layer with strides=2, while the number of filter maps is\n","    doubled. Within each stage, the layers have the same number filters and the\n","    same filter map sizes.\n","    Features maps sizes:\n","    conv1  : 32x32,  16\n","    stage 0: 32x32,  64\n","    stage 1: 16x16, 128\n","    stage 2:  8x8,  256\n","    # Arguments\n","        input_shape (tensor): shape of input image tensor\n","        depth (int): number of core convolutional layers\n","        num_classes (int): number of classes (CIFAR10 has 10)\n","    # Returns\n","        model (Model): Keras model instance\n","    \"\"\"\n","    if (depth - 2) % 9 != 0:\n","        raise ValueError('depth should be 9n+2 (eg 56 or 110 in [b])')\n","    # Start model definition.\n","    num_filters_in = 16\n","    num_res_blocks = int((depth - 2) / 9)\n","\n","    inputs = Input(shape=input_shape)\n","    # v2 performs Conv2D with BN-ReLU on input before splitting into 2 paths\n","    x = resnet_layer(inputs=inputs,\n","                     num_filters=num_filters_in,\n","                     conv_first=True)\n","\n","    # Instantiate the stack of residual units\n","    for stage in range(3):\n","        for res_block in range(num_res_blocks):\n","            activation = 'relu'\n","            batch_normalization = True\n","            strides = 1\n","            if stage == 0:\n","                num_filters_out = num_filters_in * 4\n","                if res_block == 0:  # first layer and first stage\n","                    activation = None\n","                    batch_normalization = False\n","            else:\n","                num_filters_out = num_filters_in * 2\n","                if res_block == 0:  # first layer but not first stage\n","                    strides = 2    # downsample\n","\n","            # bottleneck residual unit\n","            y = resnet_layer(inputs=x,\n","                             num_filters=num_filters_in,\n","                             kernel_size=1,\n","                             strides=strides,\n","                             activation=activation,\n","                             batch_normalization=batch_normalization,\n","                             conv_first=False)\n","            y = resnet_layer(inputs=y,\n","                             num_filters=num_filters_in,\n","                             conv_first=False)\n","            y = resnet_layer(inputs=y,\n","                             num_filters=num_filters_out,\n","                             kernel_size=1,\n","                             conv_first=False)\n","            if res_block == 0:\n","                # linear projection residual shortcut connection to match\n","                # changed dims\n","                x = resnet_layer(inputs=x,\n","                                 num_filters=num_filters_out,\n","                                 kernel_size=1,\n","                                 strides=strides,\n","                                 activation=None,\n","                                 batch_normalization=False)\n","            x = tensorflow.keras.layers.add([x, y])\n","\n","        num_filters_in = num_filters_out\n","\n","    # Add classifier on top.\n","    # v2 has BN-ReLU before Pooling\n","    x = BatchNormalization()(x)\n","    x = Activation('relu')(x)\n","    x = AveragePooling2D(pool_size=8)(x)\n","    y = Flatten()(x)\n","    outputs = Dense(num_classes,\n","                    activation='softmax',\n","                    kernel_initializer='he_normal')(y)\n","\n","    # Instantiate model.\n","    model = Model(inputs=inputs, outputs=outputs)\n","    return model"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"dr2roATRmGqd","colab_type":"code","outputId":"6585695e-e6f3-46bf-adf9-21bc96bf3106","executionInfo":{"status":"ok","timestamp":1576913898041,"user_tz":-480,"elapsed":7239,"user":{"displayName":"William Poon","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mANea9g2qMqXMcLMYHpxtuQa8Tz_yuVpCmrufBLCQ=s64","userId":"15700536326963025076"}},"colab":{"base_uri":"https://localhost:8080/","height":103}},"source":["batch_size = 64 # batch 的大小，如果出現 OOM error，請降低這個值\n","num_classes = 10 # 類別的數量，Cifar 10 共有 10 個類別\n","epochs = 30 # 訓練的 epochs 數量\n","\n","# 讀取資料集並作前處理\n","(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n","print('x_train shape:', x_train.shape)\n","print(x_train.shape[0], 'train samples')\n","print(x_test.shape[0], 'test samples')\n","x_train = x_train.astype('float32')\n","x_test = x_test.astype('float32')\n","\n","x_train = x_train / 255.\n","x_test = x_test / 255.\n","y_train = to_categorical(y_train, 10)\n","y_test = to_categorical(y_test, 10)"],"execution_count":4,"outputs":[{"output_type":"stream","text":["Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n","170500096/170498071 [==============================] - 2s 0us/step\n","x_train shape: (50000, 32, 32, 3)\n","50000 train samples\n","10000 test samples\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"fFMpqQD9vm8Y","colab_type":"code","outputId":"46b7fbdd-bffa-4328-a713-42920258d4b9","executionInfo":{"status":"ok","timestamp":1576916839623,"user_tz":-480,"elapsed":2948805,"user":{"displayName":"William Poon","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mANea9g2qMqXMcLMYHpxtuQa8Tz_yuVpCmrufBLCQ=s64","userId":"15700536326963025076"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["# Build TPU Model\n","resolver = tf.contrib.cluster_resolver.TPUClusterResolver('grpc://' + os.environ['COLAB_TPU_ADDR'])\n","tf.contrib.distribute.initialize_tpu_system(resolver)\n","strategy = tf.contrib.distribute.TPUStrategy(resolver)\n","\n","with strategy.scope():\n","  # 建立 ResNet 模型\n","  model = resnet(input_shape=(32,32,3)) \n","  model.summary()\n","  model.compile(loss='categorical_crossentropy',\n","              optimizer=tf.keras.optimizers.RMSprop(),\n","              metrics=['accuracy'])\n","\n","history = model.fit(x_train, y_train,\n","                    batch_size=batch_size,\n","                    steps_per_epoch= len(x_train)// batch_size,\n","                    epochs=epochs,\n","                    verbose=1,\n","                    validation_data=(x_test, y_test))\n","\n"],"execution_count":5,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:\n","The TensorFlow contrib module will not be included in TensorFlow 2.0.\n","For more information, please see:\n","  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n","  * https://github.com/tensorflow/addons\n","  * https://github.com/tensorflow/io (for I/O related ops)\n","If you depend on functionality not listed there, please file an issue.\n","\n","INFO:tensorflow:Initializing the TPU system: 10.23.0.2:8470\n","INFO:tensorflow:Finished initializing TPU system.\n","INFO:tensorflow:Querying Tensorflow master (grpc://10.23.0.2:8470) for TPU system metadata.\n","INFO:tensorflow:Found TPU system:\n","INFO:tensorflow:*** Num TPU Cores: 8\n","INFO:tensorflow:*** Num TPU Workers: 1\n","INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n","INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, -1, 785325319672656595)\n","INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 17179869184, 6669806207799718145)\n","INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 17179869184, 11661019818920568823)\n","INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 17179869184, 5601456674387836366)\n","INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 17179869184, 10409388973633128334)\n","INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 17179869184, 8308652283208672060)\n","INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 17179869184, 13856905574513183623)\n","INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 17179869184, 9300601039639615328)\n","INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 17179869184, 15124105226749654342)\n","INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 8589934592, 9003764170865152601)\n","INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 17179869184, 7230176095896147175)\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n","Instructions for updating:\n","If using Keras pass *_constraint arguments to layers.\n","Model: \"model\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_1 (InputLayer)            [(None, 32, 32, 3)]  0                                            \n","__________________________________________________________________________________________________\n","conv2d (Conv2D)                 (None, 32, 32, 16)   448         input_1[0][0]                    \n","__________________________________________________________________________________________________\n","batch_normalization (BatchNorma (None, 32, 32, 16)   64          conv2d[0][0]                     \n","__________________________________________________________________________________________________\n","activation (Activation)         (None, 32, 32, 16)   0           batch_normalization[0][0]        \n","__________________________________________________________________________________________________\n","conv2d_1 (Conv2D)               (None, 32, 32, 16)   272         activation[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_1 (BatchNor (None, 32, 32, 16)   64          conv2d_1[0][0]                   \n","__________________________________________________________________________________________________\n","activation_1 (Activation)       (None, 32, 32, 16)   0           batch_normalization_1[0][0]      \n","__________________________________________________________________________________________________\n","conv2d_2 (Conv2D)               (None, 32, 32, 16)   2320        activation_1[0][0]               \n","__________________________________________________________________________________________________\n","batch_normalization_2 (BatchNor (None, 32, 32, 16)   64          conv2d_2[0][0]                   \n","__________________________________________________________________________________________________\n","activation_2 (Activation)       (None, 32, 32, 16)   0           batch_normalization_2[0][0]      \n","__________________________________________________________________________________________________\n","conv2d_4 (Conv2D)               (None, 32, 32, 64)   1088        activation[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_3 (Conv2D)               (None, 32, 32, 64)   1088        activation_2[0][0]               \n","__________________________________________________________________________________________________\n","add (Add)                       (None, 32, 32, 64)   0           conv2d_4[0][0]                   \n","                                                                 conv2d_3[0][0]                   \n","__________________________________________________________________________________________________\n","batch_normalization_3 (BatchNor (None, 32, 32, 64)   256         add[0][0]                        \n","__________________________________________________________________________________________________\n","activation_3 (Activation)       (None, 32, 32, 64)   0           batch_normalization_3[0][0]      \n","__________________________________________________________________________________________________\n","conv2d_5 (Conv2D)               (None, 32, 32, 16)   1040        activation_3[0][0]               \n","__________________________________________________________________________________________________\n","batch_normalization_4 (BatchNor (None, 32, 32, 16)   64          conv2d_5[0][0]                   \n","__________________________________________________________________________________________________\n","activation_4 (Activation)       (None, 32, 32, 16)   0           batch_normalization_4[0][0]      \n","__________________________________________________________________________________________________\n","conv2d_6 (Conv2D)               (None, 32, 32, 16)   2320        activation_4[0][0]               \n","__________________________________________________________________________________________________\n","batch_normalization_5 (BatchNor (None, 32, 32, 16)   64          conv2d_6[0][0]                   \n","__________________________________________________________________________________________________\n","activation_5 (Activation)       (None, 32, 32, 16)   0           batch_normalization_5[0][0]      \n","__________________________________________________________________________________________________\n","conv2d_7 (Conv2D)               (None, 32, 32, 64)   1088        activation_5[0][0]               \n","__________________________________________________________________________________________________\n","add_1 (Add)                     (None, 32, 32, 64)   0           add[0][0]                        \n","                                                                 conv2d_7[0][0]                   \n","__________________________________________________________________________________________________\n","batch_normalization_6 (BatchNor (None, 32, 32, 64)   256         add_1[0][0]                      \n","__________________________________________________________________________________________________\n","activation_6 (Activation)       (None, 32, 32, 64)   0           batch_normalization_6[0][0]      \n","__________________________________________________________________________________________________\n","conv2d_8 (Conv2D)               (None, 32, 32, 16)   1040        activation_6[0][0]               \n","__________________________________________________________________________________________________\n","batch_normalization_7 (BatchNor (None, 32, 32, 16)   64          conv2d_8[0][0]                   \n","__________________________________________________________________________________________________\n","activation_7 (Activation)       (None, 32, 32, 16)   0           batch_normalization_7[0][0]      \n","__________________________________________________________________________________________________\n","conv2d_9 (Conv2D)               (None, 32, 32, 16)   2320        activation_7[0][0]               \n","__________________________________________________________________________________________________\n","batch_normalization_8 (BatchNor (None, 32, 32, 16)   64          conv2d_9[0][0]                   \n","__________________________________________________________________________________________________\n","activation_8 (Activation)       (None, 32, 32, 16)   0           batch_normalization_8[0][0]      \n","__________________________________________________________________________________________________\n","conv2d_10 (Conv2D)              (None, 32, 32, 64)   1088        activation_8[0][0]               \n","__________________________________________________________________________________________________\n","add_2 (Add)                     (None, 32, 32, 64)   0           add_1[0][0]                      \n","                                                                 conv2d_10[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_9 (BatchNor (None, 32, 32, 64)   256         add_2[0][0]                      \n","__________________________________________________________________________________________________\n","activation_9 (Activation)       (None, 32, 32, 64)   0           batch_normalization_9[0][0]      \n","__________________________________________________________________________________________________\n","conv2d_11 (Conv2D)              (None, 16, 16, 64)   4160        activation_9[0][0]               \n","__________________________________________________________________________________________________\n","batch_normalization_10 (BatchNo (None, 16, 16, 64)   256         conv2d_11[0][0]                  \n","__________________________________________________________________________________________________\n","activation_10 (Activation)      (None, 16, 16, 64)   0           batch_normalization_10[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_12 (Conv2D)              (None, 16, 16, 64)   36928       activation_10[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_11 (BatchNo (None, 16, 16, 64)   256         conv2d_12[0][0]                  \n","__________________________________________________________________________________________________\n","activation_11 (Activation)      (None, 16, 16, 64)   0           batch_normalization_11[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_14 (Conv2D)              (None, 16, 16, 128)  8320        add_2[0][0]                      \n","__________________________________________________________________________________________________\n","conv2d_13 (Conv2D)              (None, 16, 16, 128)  8320        activation_11[0][0]              \n","__________________________________________________________________________________________________\n","add_3 (Add)                     (None, 16, 16, 128)  0           conv2d_14[0][0]                  \n","                                                                 conv2d_13[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_12 (BatchNo (None, 16, 16, 128)  512         add_3[0][0]                      \n","__________________________________________________________________________________________________\n","activation_12 (Activation)      (None, 16, 16, 128)  0           batch_normalization_12[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_15 (Conv2D)              (None, 16, 16, 64)   8256        activation_12[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_13 (BatchNo (None, 16, 16, 64)   256         conv2d_15[0][0]                  \n","__________________________________________________________________________________________________\n","activation_13 (Activation)      (None, 16, 16, 64)   0           batch_normalization_13[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_16 (Conv2D)              (None, 16, 16, 64)   36928       activation_13[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_14 (BatchNo (None, 16, 16, 64)   256         conv2d_16[0][0]                  \n","__________________________________________________________________________________________________\n","activation_14 (Activation)      (None, 16, 16, 64)   0           batch_normalization_14[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_17 (Conv2D)              (None, 16, 16, 128)  8320        activation_14[0][0]              \n","__________________________________________________________________________________________________\n","add_4 (Add)                     (None, 16, 16, 128)  0           add_3[0][0]                      \n","                                                                 conv2d_17[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_15 (BatchNo (None, 16, 16, 128)  512         add_4[0][0]                      \n","__________________________________________________________________________________________________\n","activation_15 (Activation)      (None, 16, 16, 128)  0           batch_normalization_15[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_18 (Conv2D)              (None, 16, 16, 64)   8256        activation_15[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_16 (BatchNo (None, 16, 16, 64)   256         conv2d_18[0][0]                  \n","__________________________________________________________________________________________________\n","activation_16 (Activation)      (None, 16, 16, 64)   0           batch_normalization_16[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_19 (Conv2D)              (None, 16, 16, 64)   36928       activation_16[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_17 (BatchNo (None, 16, 16, 64)   256         conv2d_19[0][0]                  \n","__________________________________________________________________________________________________\n","activation_17 (Activation)      (None, 16, 16, 64)   0           batch_normalization_17[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_20 (Conv2D)              (None, 16, 16, 128)  8320        activation_17[0][0]              \n","__________________________________________________________________________________________________\n","add_5 (Add)                     (None, 16, 16, 128)  0           add_4[0][0]                      \n","                                                                 conv2d_20[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_18 (BatchNo (None, 16, 16, 128)  512         add_5[0][0]                      \n","__________________________________________________________________________________________________\n","activation_18 (Activation)      (None, 16, 16, 128)  0           batch_normalization_18[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_21 (Conv2D)              (None, 8, 8, 128)    16512       activation_18[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_19 (BatchNo (None, 8, 8, 128)    512         conv2d_21[0][0]                  \n","__________________________________________________________________________________________________\n","activation_19 (Activation)      (None, 8, 8, 128)    0           batch_normalization_19[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_22 (Conv2D)              (None, 8, 8, 128)    147584      activation_19[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_20 (BatchNo (None, 8, 8, 128)    512         conv2d_22[0][0]                  \n","__________________________________________________________________________________________________\n","activation_20 (Activation)      (None, 8, 8, 128)    0           batch_normalization_20[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_24 (Conv2D)              (None, 8, 8, 256)    33024       add_5[0][0]                      \n","__________________________________________________________________________________________________\n","conv2d_23 (Conv2D)              (None, 8, 8, 256)    33024       activation_20[0][0]              \n","__________________________________________________________________________________________________\n","add_6 (Add)                     (None, 8, 8, 256)    0           conv2d_24[0][0]                  \n","                                                                 conv2d_23[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_21 (BatchNo (None, 8, 8, 256)    1024        add_6[0][0]                      \n","__________________________________________________________________________________________________\n","activation_21 (Activation)      (None, 8, 8, 256)    0           batch_normalization_21[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_25 (Conv2D)              (None, 8, 8, 128)    32896       activation_21[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_22 (BatchNo (None, 8, 8, 128)    512         conv2d_25[0][0]                  \n","__________________________________________________________________________________________________\n","activation_22 (Activation)      (None, 8, 8, 128)    0           batch_normalization_22[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_26 (Conv2D)              (None, 8, 8, 128)    147584      activation_22[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_23 (BatchNo (None, 8, 8, 128)    512         conv2d_26[0][0]                  \n","__________________________________________________________________________________________________\n","activation_23 (Activation)      (None, 8, 8, 128)    0           batch_normalization_23[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_27 (Conv2D)              (None, 8, 8, 256)    33024       activation_23[0][0]              \n","__________________________________________________________________________________________________\n","add_7 (Add)                     (None, 8, 8, 256)    0           add_6[0][0]                      \n","                                                                 conv2d_27[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_24 (BatchNo (None, 8, 8, 256)    1024        add_7[0][0]                      \n","__________________________________________________________________________________________________\n","activation_24 (Activation)      (None, 8, 8, 256)    0           batch_normalization_24[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_28 (Conv2D)              (None, 8, 8, 128)    32896       activation_24[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_25 (BatchNo (None, 8, 8, 128)    512         conv2d_28[0][0]                  \n","__________________________________________________________________________________________________\n","activation_25 (Activation)      (None, 8, 8, 128)    0           batch_normalization_25[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_29 (Conv2D)              (None, 8, 8, 128)    147584      activation_25[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_26 (BatchNo (None, 8, 8, 128)    512         conv2d_29[0][0]                  \n","__________________________________________________________________________________________________\n","activation_26 (Activation)      (None, 8, 8, 128)    0           batch_normalization_26[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_30 (Conv2D)              (None, 8, 8, 256)    33024       activation_26[0][0]              \n","__________________________________________________________________________________________________\n","add_8 (Add)                     (None, 8, 8, 256)    0           add_7[0][0]                      \n","                                                                 conv2d_30[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_27 (BatchNo (None, 8, 8, 256)    1024        add_8[0][0]                      \n","__________________________________________________________________________________________________\n","activation_27 (Activation)      (None, 8, 8, 256)    0           batch_normalization_27[0][0]     \n","__________________________________________________________________________________________________\n","average_pooling2d (AveragePooli (None, 1, 1, 256)    0           activation_27[0][0]              \n","__________________________________________________________________________________________________\n","flatten (Flatten)               (None, 256)          0           average_pooling2d[0][0]          \n","__________________________________________________________________________________________________\n","dense (Dense)                   (None, 10)           2570        flatten[0][0]                    \n","==================================================================================================\n","Total params: 849,002\n","Trainable params: 843,786\n","Non-trainable params: 5,216\n","__________________________________________________________________________________________________\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/layers/normalization.py:477: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.where in 2.0, which has the same broadcast rule as np.where\n","Epoch 1/30\n","780/781 [============================>.] - ETA: 0s - loss: 1.9533 - acc: 0.4715INFO:tensorflow:Running validation at fit epoch: 0\n","157/157 [==============================] - 15s 95ms/step\n","157/157 [==============================] - 15s 95ms/step\n","781/781 [==============================] - 39s 49ms/step - loss: 1.9528 - acc: 0.4716 - val_loss: 1.8800 - val_acc: 0.4785\n","Epoch 2/30\n","777/781 [============================>.] - ETA: 0s - loss: 1.4740 - acc: 0.6144INFO:tensorflow:Running validation at fit epoch: 1\n","157/157 [==============================] - 17s 106ms/step\n","157/157 [==============================] - 17s 106ms/step\n","781/781 [==============================] - 36s 46ms/step - loss: 1.4731 - acc: 0.6148 - val_loss: 1.7063 - val_acc: 0.5595\n","Epoch 3/30\n","777/781 [============================>.] - ETA: 0s - loss: 1.2496 - acc: 0.6825INFO:tensorflow:Running validation at fit epoch: 2\n","157/157 [==============================] - 19s 120ms/step\n","157/157 [==============================] - 19s 120ms/step\n","781/781 [==============================] - 40s 51ms/step - loss: 1.2494 - acc: 0.6826 - val_loss: 1.4335 - val_acc: 0.6569\n","Epoch 4/30\n","779/781 [============================>.] - ETA: 0s - loss: 1.1103 - acc: 0.7293INFO:tensorflow:Running validation at fit epoch: 3\n","157/157 [==============================] - 20s 130ms/step\n","157/157 [==============================] - 20s 130ms/step\n","781/781 [==============================] - 42s 54ms/step - loss: 1.1102 - acc: 0.7293 - val_loss: 1.5019 - val_acc: 0.6388\n","Epoch 5/30\n","778/781 [============================>.] - ETA: 0s - loss: 1.0164 - acc: 0.7592INFO:tensorflow:Running validation at fit epoch: 4\n","157/157 [==============================] - 23s 143ms/step\n","157/157 [==============================] - 23s 143ms/step\n","781/781 [==============================] - 46s 59ms/step - loss: 1.0165 - acc: 0.7591 - val_loss: 1.4282 - val_acc: 0.6588\n","Epoch 6/30\n","778/781 [============================>.] - ETA: 0s - loss: 0.9447 - acc: 0.7835INFO:tensorflow:Running validation at fit epoch: 5\n","157/157 [==============================] - 25s 162ms/step\n","157/157 [==============================] - 25s 162ms/step\n","781/781 [==============================] - 50s 63ms/step - loss: 0.9442 - acc: 0.7835 - val_loss: 1.2844 - val_acc: 0.6770\n","Epoch 7/30\n","777/781 [============================>.] - ETA: 0s - loss: 0.8880 - acc: 0.8002INFO:tensorflow:Running validation at fit epoch: 6\n","157/157 [==============================] - 27s 172ms/step\n","157/157 [==============================] - 27s 172ms/step\n","781/781 [==============================] - 53s 68ms/step - loss: 0.8880 - acc: 0.8001 - val_loss: 1.4397 - val_acc: 0.6590\n","Epoch 8/30\n","778/781 [============================>.] - ETA: 0s - loss: 0.8485 - acc: 0.8157INFO:tensorflow:Running validation at fit epoch: 7\n","157/157 [==============================] - 30s 190ms/step\n","157/157 [==============================] - 30s 190ms/step\n","781/781 [==============================] - 57s 73ms/step - loss: 0.8483 - acc: 0.8157 - val_loss: 1.2111 - val_acc: 0.7153\n","Epoch 9/30\n","779/781 [============================>.] - ETA: 0s - loss: 0.7985 - acc: 0.8321INFO:tensorflow:Running validation at fit epoch: 8\n","157/157 [==============================] - 32s 205ms/step\n","157/157 [==============================] - 32s 205ms/step\n","781/781 [==============================] - 61s 78ms/step - loss: 0.7983 - acc: 0.8322 - val_loss: 1.1196 - val_acc: 0.7386\n","Epoch 10/30\n","778/781 [============================>.] - ETA: 0s - loss: 0.7724 - acc: 0.8413INFO:tensorflow:Running validation at fit epoch: 9\n","157/157 [==============================] - 35s 220ms/step\n","157/157 [==============================] - 35s 220ms/step\n","781/781 [==============================] - 65s 83ms/step - loss: 0.7720 - acc: 0.8414 - val_loss: 1.1034 - val_acc: 0.7444\n","Epoch 11/30\n","777/781 [============================>.] - ETA: 0s - loss: 0.7455 - acc: 0.8520INFO:tensorflow:Running validation at fit epoch: 10\n","157/157 [==============================] - 36s 228ms/step\n","157/157 [==============================] - 36s 228ms/step\n","781/781 [==============================] - 68s 87ms/step - loss: 0.7452 - acc: 0.8520 - val_loss: 1.7921 - val_acc: 0.6260\n","Epoch 12/30\n","777/781 [============================>.] - ETA: 0s - loss: 0.7242 - acc: 0.8612INFO:tensorflow:Running validation at fit epoch: 11\n","157/157 [==============================] - 39s 251ms/step\n","157/157 [==============================] - 39s 251ms/step\n","781/781 [==============================] - 74s 94ms/step - loss: 0.7238 - acc: 0.8614 - val_loss: 1.8206 - val_acc: 0.6074\n","Epoch 13/30\n","777/781 [============================>.] - ETA: 0s - loss: 0.6999 - acc: 0.8687INFO:tensorflow:Running validation at fit epoch: 12\n","157/157 [==============================] - 43s 277ms/step\n","157/157 [==============================] - 43s 277ms/step\n","781/781 [==============================] - 78s 100ms/step - loss: 0.6995 - acc: 0.8688 - val_loss: 1.1938 - val_acc: 0.7416\n","Epoch 14/30\n","777/781 [============================>.] - ETA: 0s - loss: 0.6883 - acc: 0.8762INFO:tensorflow:Running validation at fit epoch: 13\n","157/157 [==============================] - 43s 275ms/step\n","157/157 [==============================] - 43s 275ms/step\n","781/781 [==============================] - 79s 102ms/step - loss: 0.6878 - acc: 0.8765 - val_loss: 1.0446 - val_acc: 0.7721\n","Epoch 15/30\n","777/781 [============================>.] - ETA: 0s - loss: 0.6763 - acc: 0.8793INFO:tensorflow:Running validation at fit epoch: 14\n","157/157 [==============================] - 50s 316ms/step\n","157/157 [==============================] - 50s 316ms/step\n","781/781 [==============================] - 89s 114ms/step - loss: 0.6761 - acc: 0.8794 - val_loss: 1.2560 - val_acc: 0.7414\n","Epoch 16/30\n","778/781 [============================>.] - ETA: 0s - loss: 0.6572 - acc: 0.8880INFO:tensorflow:Running validation at fit epoch: 15\n","157/157 [==============================] - 50s 321ms/step\n","157/157 [==============================] - 50s 321ms/step\n","781/781 [==============================] - 90s 115ms/step - loss: 0.6571 - acc: 0.8880 - val_loss: 1.3211 - val_acc: 0.7253\n","Epoch 17/30\n","778/781 [============================>.] - ETA: 0s - loss: 0.6524 - acc: 0.8911INFO:tensorflow:Running validation at fit epoch: 16\n","157/157 [==============================] - 56s 355ms/step\n","157/157 [==============================] - 56s 355ms/step\n","781/781 [==============================] - 100s 128ms/step - loss: 0.6524 - acc: 0.8911 - val_loss: 1.2225 - val_acc: 0.7278\n","Epoch 18/30\n","777/781 [============================>.] - ETA: 0s - loss: 0.6405 - acc: 0.8976INFO:tensorflow:Running validation at fit epoch: 17\n","157/157 [==============================] - 60s 384ms/step\n","157/157 [==============================] - 60s 384ms/step\n","781/781 [==============================] - 105s 134ms/step - loss: 0.6404 - acc: 0.8975 - val_loss: 1.5038 - val_acc: 0.7202\n","Epoch 19/30\n","780/781 [============================>.] - ETA: 0s - loss: 0.6368 - acc: 0.8997INFO:tensorflow:Running validation at fit epoch: 18\n","157/157 [==============================] - 59s 374ms/step\n","157/157 [==============================] - 59s 374ms/step\n","781/781 [==============================] - 105s 134ms/step - loss: 0.6367 - acc: 0.8996 - val_loss: 1.2072 - val_acc: 0.7618\n","Epoch 20/30\n","778/781 [============================>.] - ETA: 0s - loss: 0.6286 - acc: 0.9004INFO:tensorflow:Running validation at fit epoch: 19\n","157/157 [==============================] - 61s 392ms/step\n","157/157 [==============================] - 61s 392ms/step\n","781/781 [==============================] - 109s 139ms/step - loss: 0.6287 - acc: 0.9004 - val_loss: 1.0884 - val_acc: 0.7817\n","Epoch 21/30\n","780/781 [============================>.] - ETA: 0s - loss: 0.6160 - acc: 0.9058INFO:tensorflow:Running validation at fit epoch: 20\n","157/157 [==============================] - 71s 450ms/step\n","157/157 [==============================] - 71s 450ms/step\n","781/781 [==============================] - 126s 161ms/step - loss: 0.6162 - acc: 0.9058 - val_loss: 1.5013 - val_acc: 0.7130\n","Epoch 22/30\n","780/781 [============================>.] - ETA: 0s - loss: 0.6134 - acc: 0.9102INFO:tensorflow:Running validation at fit epoch: 21\n","157/157 [==============================] - 77s 489ms/step\n","157/157 [==============================] - 77s 489ms/step\n","781/781 [==============================] - 131s 168ms/step - loss: 0.6134 - acc: 0.9102 - val_loss: 1.7185 - val_acc: 0.6862\n","Epoch 23/30\n","779/781 [============================>.] - ETA: 0s - loss: 0.6120 - acc: 0.9110INFO:tensorflow:Running validation at fit epoch: 22\n","157/157 [==============================] - 76s 483ms/step\n","157/157 [==============================] - 76s 483ms/step\n","781/781 [==============================] - 134s 171ms/step - loss: 0.6121 - acc: 0.9111 - val_loss: 1.3346 - val_acc: 0.7232\n","Epoch 24/30\n","777/781 [============================>.] - ETA: 0s - loss: 0.6035 - acc: 0.9119INFO:tensorflow:Running validation at fit epoch: 23\n","157/157 [==============================] - 76s 482ms/step\n","157/157 [==============================] - 76s 482ms/step\n","781/781 [==============================] - 131s 168ms/step - loss: 0.6036 - acc: 0.9120 - val_loss: 1.1980 - val_acc: 0.7607\n","Epoch 25/30\n","779/781 [============================>.] - ETA: 0s - loss: 0.5993 - acc: 0.9145INFO:tensorflow:Running validation at fit epoch: 24\n","157/157 [==============================] - 85s 540ms/step\n","157/157 [==============================] - 85s 540ms/step\n","781/781 [==============================] - 147s 188ms/step - loss: 0.5993 - acc: 0.9145 - val_loss: 1.4086 - val_acc: 0.7250\n","Epoch 26/30\n","777/781 [============================>.] - ETA: 0s - loss: 0.5932 - acc: 0.9185INFO:tensorflow:Running validation at fit epoch: 25\n","157/157 [==============================] - 91s 577ms/step\n","157/157 [==============================] - 91s 577ms/step\n","781/781 [==============================] - 156s 200ms/step - loss: 0.5931 - acc: 0.9186 - val_loss: 1.4759 - val_acc: 0.6995\n","Epoch 27/30\n","777/781 [============================>.] - ETA: 0s - loss: 0.5889 - acc: 0.9200INFO:tensorflow:Running validation at fit epoch: 26\n","157/157 [==============================] - 92s 589ms/step\n","157/157 [==============================] - 92s 589ms/step\n","781/781 [==============================] - 155s 198ms/step - loss: 0.5890 - acc: 0.9200 - val_loss: 1.4207 - val_acc: 0.7351\n","Epoch 28/30\n","777/781 [============================>.] - ETA: 0s - loss: 0.5876 - acc: 0.9208INFO:tensorflow:Running validation at fit epoch: 27\n","157/157 [==============================] - 100s 636ms/step\n","157/157 [==============================] - 100s 636ms/step\n","781/781 [==============================] - 166s 213ms/step - loss: 0.5876 - acc: 0.9208 - val_loss: 1.6435 - val_acc: 0.7145\n","Epoch 29/30\n","780/781 [============================>.] - ETA: 0s - loss: 0.5840 - acc: 0.9209INFO:tensorflow:Running validation at fit epoch: 28\n","157/157 [==============================] - 102s 649ms/step\n","157/157 [==============================] - 102s 649ms/step\n","781/781 [==============================] - 169s 216ms/step - loss: 0.5840 - acc: 0.9209 - val_loss: 1.1099 - val_acc: 0.7811\n","Epoch 30/30\n","777/781 [============================>.] - ETA: 0s - loss: 0.5745 - acc: 0.9251INFO:tensorflow:Running validation at fit epoch: 29\n","157/157 [==============================] - 110s 700ms/step\n","157/157 [==============================] - 110s 700ms/step\n","781/781 [==============================] - 179s 230ms/step - loss: 0.5744 - acc: 0.9251 - val_loss: 1.2956 - val_acc: 0.7463\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"WyoR6rsfR5aL","colab_type":"code","colab":{}},"source":["#model.save_weights('./D100.h5', overwrite=True)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"bSaRoOqcmGqm","colab_type":"code","outputId":"10340719-b46a-40c4-d11f-808e89e86cdb","executionInfo":{"status":"ok","timestamp":1576917130006,"user_tz":-480,"elapsed":3239173,"user":{"displayName":"William Poon","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mANea9g2qMqXMcLMYHpxtuQa8Tz_yuVpCmrufBLCQ=s64","userId":"15700536326963025076"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["score = model.evaluate(x_test, y_test, verbose=0)\n","print('Test loss:', score[0])\n","print('Test accuracy:', score[1])"],"execution_count":7,"outputs":[{"output_type":"stream","text":["Test loss: 1.2950439380761534\n","Test accuracy: 0.7468\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"BripxPpXmGqp","colab_type":"text"},"source":["## 作業\n","礙於不是所有同學都有 GPU ，這邊的範例使用的是簡化版本的 ResNet，確保所有同學都能夠訓練!\n","\n","最後一天的作業請閱讀這篇[非常詳盡的文章](https://blog.gtwang.org/programming/keras-resnet-50-pre-trained-model-build-dogs-cats-image-classification-system/)，基本上已經涵蓋了所有訓練　CNN 常用的技巧，請使用所有學過的訓練技巧，盡可能地提高 Cifar-10 的 test data 準確率，截圖你最佳的結果並上傳來完成最後一次的作業吧!\n","\n","另外這些技巧在 Kaggle 上也會被許多人使用，更有人會開發一些新的技巧，例如使把預訓練在 ImageNet 上的模型當成 feature extractor 後，再拿擷取出的特徵重新訓練新的模型，這些技巧再進階的課程我們會在提到，有興趣的同學也可以[參考](https://www.kaggle.com/insaff/img-feature-extraction-with-pretrained-resnet"]},{"cell_type":"markdown","metadata":{"id":"CSgFr3ovmGqq","colab_type":"text"},"source":["## 進階挑戰!\n","有志以成為機器學習工程師為目標的同學們可以參加這個挑戰，這[網站](https://rodrigob.github.io/are_we_there_yet/build/classification_datasets_results.html#43494641522d3130)記錄了歷年來 Cifar-10 中排名最高的論文，請試著閱讀論文並撰寫出相對應的程式碼，復現出論文的結果。\n","\n","這樣的能力在機器學習領域中是非常重要的，具備閱讀他人論文並實現的能力，可為自己在履歷上增添不少分數，當然難度也相當高，若是不透徹了解文章內容或是程式能力不夠紮實，可是不能復現別人辛苦的研究成果的喔! 就請各位同學好好努力，往自己的機器學習之路邁進吧:)"]},{"cell_type":"code","metadata":{"id":"S3NAXLramGqr","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}